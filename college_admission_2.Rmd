---
title: "College Admission"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Project



```{r}
install.packages("pscl", repos = "https://cran.rstudio.com")
library("ggplot2")
library("naivebayes")
library("class")
library("rpart")
library("rpart.plot")
library("e1071")
library("caret")
library("caTools")

d<-read.csv("E:\\Simpli Learn\\6.Data science with R\\R Projects\\5_College admission project\\College_admission.csv",header=T)
head(d)
d1<-d

#no. of records
nrow(d)

#datatype of columns
sapply(d,class)

#converting columns to factor type
cols<-c("admit","ses","Gender_Male","Race","rank")
d[cols]<-lapply(d[cols],factor)
sapply(d,class)
d$gre<-as.numeric(d$gre)

#Outlier detection
# for gre variable
boxplot(d)
iqr1<-IQR(d$gre)
Q1<-quantile(d$gre,probs = c(.25,.75), na.rm=F)
eliminated<-subset(d,d$gre > (Q1[1]-1.5*iqr1) & d$gre < (Q1[2]+1.5*iqr1))
d<-subset(eliminated,eliminated$gre > (Q1[1]-1.5*iqr1) & eliminated$gre < (Q1[2]+1.5*iqr1))
remove(eliminated)

iqr2<-IQR(d$gpa)
Q2<-quantile(d$gpa,probs = c(.25,.75), na.rm=F)
eliminated<-subset(d,d$gpa > (Q2[1]-1.5*iqr2) & d$gpa < (Q2[2]+1.5*iqr2))
d<-subset(eliminated,eliminated$gpa > (Q2[1]-1.5*iqr2) & eliminated$gpa < (Q2[2]+1.5*iqr2))
remove(eliminated)
#iqr1<-IQR(d$gre)
#iqr1
#quantile(d$gre, na.rm=TRUE)
#max1<-660+1.5*iqr1
#max1
#min1<-520-1.5*iqr1
#min1
#all points above upper inner fence
#print(which(d$gre > max1))
#all points above lower inner fence
#print(which(d$gpa < min1))
#Removing outlier
#d<-d[-c(72,180,290,305,316),]
#nrow(d)

#step4: find the data distribution
hist(d$gre,col="Red", main="Graduate record exam score")
hist(d$gpa,col="Yellow", main="Grade point average")

#step5: Normalize the data if not normally distributed
#normalize<-function(x){
#  return((x-min(x))/(max(x)-min(x)))
#}

# Normalize the gre col:
#gre<-as.data.frame(lapply(d$gre,normalize))
#hist(gre, col="Red", main="Graduate record Exam score after Norm")

#Scaling
d$gre<-scale(d$gre,center = TRUE,scale=TRUE)
d$gpa<-scale(d$gpa,center = TRUE,scale=TRUE)


#splitting dataset into train and test
set.seed(123)

d[,2:3]<-scale(d[,2:3])
split<-sample.split(d$admit, SplitRatio=.75)
train<-subset(d,split==T)
test<-subset(d,split==F)

#Logistic regression (compare it with live class room example)
logi1<-glm(admit~.,data=train,family='binomial')
summary(logi1)

# model 2 with significant data (compare it with live class room example)
logi2<-glm(admit~gre+gpa,data=train,family='binomial')
summary(logi2)
#Here residual deviation increases so we will use first model 
glm_predict<-predict(logi1,test,type="response")
test$pred_admit1<-ifelse(glm_predict>0.5,1,0)

#confusion matrix

confusionMatrix(as.factor(test$pred_admit1),test$admit)
# OR #
#conf_mat1<-table(predicted=test$pred_admit1,actual=test$admit)
#conf_mat1

#accuracy
#accuracy1<-sum(diag(conf_mat1))/sum(conf_mat1)
#accuracy1

#============================================
#SVM model

svm_clf=svm(admit~.,data=train,type ='C-classification',kernel='linear')
summary(svm_clf)
predicted_val2<-predict(svm_clf,test[-1])
predicted_val2
#test$pred_admit2<-ifelse(predicted_val2>0.5,1,0)
#confusionMatrix(svm_predict,test$admit)

confusionMatrix(predicted_val2,test$admit,positive = '1')
#confusion matrix
#conf_mat2<-table(predicted=predicted_val2,actual=test$admit)
#conf_mat2

#accuracy
#accuracy2<-sum(diag(conf_mat2))/sum(conf_mat2)
#accuracy2

#Decision tree

nrow(train)
nrow(test)
0.03*nrow(train)
0.03*nrow(train)*3
r.cntrl<-rpart.control(minsplit=26, minbucket=9,xval=5)
dec_clf<-rpart(admit~.,control=r.cntrl,data=train)
rpart.plot(dec_clf)
summary(dec_clf)
predicted_val3<-predict(dec_clf,test[-1],type="class")
predicted_val3

confusionMatrix(predicted_val3,test$admit,positive = '1')
#confusion_matrix
#conf_mat3<-table(predicted=predicted_val3,actual=test$admit)
#conf_mat3

#accuracy
#accuracy3<-sum(diag(conf_mat3))/sum(conf_mat3)
#accuracy3
#================================================
#knn 

knn=knn(train, test[-1], train$admit, k=19)
knn
confusionMatrix(knn,test$admit,positive = '1')

#confusion_matrix
#conf_mat4<-table(predicted=knn,actual=test$admit)
#conf_mat4

#accuracy
#accuracy4<-sum(diag(conf_mat4))/sum(conf_mat4)
#accuracy4

#================================================
# Naive bayes

nb<-naive_bayes(admit~.,data=train)
nb
predicted_val5<-predict(nb, test[-1], type="class")
confusionMatrix(predicted_val5,test$admit,positive = '1')

#confusion_matrix
#conf_mat5<-table(predicted=predicted_val5,actual=test$admit)
#conf_mat5

#accuracy
#accuracy5<-sum(diag(conf_mat5))/sum(conf_mat5)
#accuracy5

#================================================
#Logistic regression
#logistic regression and svm are the best model with accuracy=61.61% 

#Categorize the grade point average into High, Medium, and Low (with admission probability percentages) and plot it on a point chart. 

Descriptive=transform(d1,GreLevels=ifelse(gre<440,"Low",ifelse(gre<580,"Medium","High")))
View(Descriptive)
Sum_Desc=aggregate(admit~GreLevels,Descriptive,FUN=sum)
length_Desc=aggregate(admit~GreLevels,Descriptive,FUN=length)
Probability_Table=cbind(Sum_Desc,Recs=length_Desc[,2])
Probability_Table_final=transform(Probability_Table,Probability_Admission=admit/Recs)

ggplot(Probability_Table_final,aes(x=GreLevels,y=Probability_Admission))+geom_point()

#cross grid for admission variable with GRE categorized

table(Descriptive$admit,Descriptive$GreLevels)


```
